{
    "goal": "\n    Create a blog post that relates to the datasources for a socail media AI company of araound 500 words. \n    The company is called South River AI they are developing Athena a social media interaction application.\n    The application is designed to help users interact with social media in a more productive way. \n    It systhesizes posts from a variety of sources and presents them to the user in a way that is more condusive to productivity.\n    ",
    "list_data_source": [{
            "title": "Fake It 'Til You Fake It",
            "url": "https://pxlnv.com/blog/fake-it-til-you-fake-it/",
            "text": "Fake It \u2019Til You Fake It \u2013 Pixel Envy\nfrom the desk of\nNick Heer.\nArticles\nAll Posts\nSponsorship\nAbout\nFake It \u2019Til You Fake It\nOctober 8, 2023\n\u2325\nSince Google\u2019s introduction of its Pixel 8 phones earlier this month, it has been interesting and a little amusing to me to read the reactions to its image manipulation tools. It feels like we have been asking the same questions every year \u2014 questions like\nwhat is a photograph, anyway?\n, and\nhas technology gone too far?\n\u2014 since Google went all-in on computational photography with its\noriginal Pixels\nin 2016. In fact, these are things which people have been asking about photography since its early development. Arguments about Google\u2019s complicity in fakery seem to be missing some historical context. Which means, unfortunately, a thousand-word summary.\nAs it happens, I took a photo history course when I was in university many years ago. I distinctly remember the instructor showing us an\n1851 image\nshot by Edouard Baldus, and revealing to us that it was not a single photo, but instead a series of exposures cut and merged into a single image in a darkroom. That blew my mind at the time because, until then, I had thought of photo manipulation as a relatively recent thing. I had heard about Joseph Stalin\u2019s propaganda efforts to\nremove officials who displeased him\n. But, surely, any manipulation that required precisely cutting negatives or painting over people was quite rare until Photoshop came along, right?\nNo. Not even close. The legacy of photography is a legacy of lies and liars.\nIn the introductory essay for the 2012 exhibition \u201cFaking It: Manipulated Photography Before Photoshop\u201d \u2014 sponsored by Adobe \u2014 Mia Fineman writes of the difference between darkroom techniques to adjust regions of a photo for exposure or cropping for composition, and photos where \u201cthe final image is not identical to what the camera \u2018saw\u2019 in the instant at which the negative was exposed\u201d.\n1\nThe catalogue features nearly two hundred years of images which fit this description: from subtle enhancements, like compositing clouds into an overexposed sky, to artistic or humorous choices \u2014 \u201c\nMan on a Rooftop with Eleven Men in Formation on His Shoulders\n\u201d is an oft-cited delight \u2014 to dastardly projections of political power. Perhaps the most insidious examples are those which seem like journalistic \u201cstraight\u201d images; one version of an\nimage of the Animas Canyon\nby William Henry Jackson includes several fictional elements not present in the\noriginal\n.\nEven at the time of manipulation-by-negative, there were questions about the legitimacy and ethics of these kinds of changes. In his 1869 essay \u201c\nPictorial Effect in Photography\n\u201d, Henry Peach Robinson writes \u201c[p]hotographs of what it is evident to our senses cannot visibly exist should never be attempted\u201d, concluding that \u201ctruth in art may exist without an absolute observance of facts\u201d. Strangely, Robinson defends photographic manipulation that would enhance the image, but disagrees with adding elements \u2014 like a \u201cgroup of cherubs\u201d \u2014 which would be purely fantastical.\nThis exhibition really was sponsored by Adobe \u2014 that was not a joke \u2014 and the company\u2019s then-senior director of digital imaging Maria Yap explained why in a statement (\nsic\n):\n2\n[\u2026] For more than twenty years \u2014 since its first release, in 1990 \u2014 Adobe\u00ae Photoshop\u00ae software has been accused of undermining photographic truthfulness. The implicit assumption has been that photographs shot before 1990 captured the unvarnished truth and that manipulations made possible by Photoshop compromised that truth.\nNow, \u201cFaking It\u201d punctures this assumption, presenting two hundred works that demonstrate the many ways photographs have been manipulated since the early days of the medium to serve artistry, novelty, politics, news, advertising, fashion, and other photographic purposes. [\u2026]\nIt was a smart public relations decision for Adobe to remind everyone that it is not responsible for manipulated images\nno matter how you phrase it\n. In fact, a few years after this exhibition debuted at New York\u2019s Metropolitan Museum of Art, Adobe acknowledged the twenty-fifth anniversary of Photoshop with a microsite that included a \u201c\nReal or Photoshop\n\u201d quiz. Several years later, there are games to test your ability to identify\nwhich person is real\n.\nThe year after Adobe\u2019s anniversary celebration, Google introduced its first Pixel phone. Each generation has leaned harder into its computational photography capabilities, with notable highlights like\nastrophotography\nin the Pixel 4,\nFace Unblur and the first iteration of Magic Eraser\nin the Pixel 6, and\nSuper Res Zoom\nin the Pixel 7 Pro. With each iteration, these technologies have moved farther away from reproducing a real scene as accurately as possible, and toward synthesizing a scene based on real-life elements.\nThe Pixel 8 continues this pattern with three features causing some consternation: an updated version of Magic Eraser, which now uses machine learning to generate patches for distracting photo elements; Best Take, which captures multiple stills of group photos and lets you choose the best face for each person; and Magic Editor, which uses more generative software to allow you to move around individual components of a photo. Google showed off the latter feature by showing\nhow a trampoline could be removed\nto make it look like someone really did make that sick slam dunk.\nJay Peters\n, of the\nVerge\n, is worried:\nThere\u2019s nothing inherently wrong with manipulating your own photos. People have done it for a very long time. But Google\u2019s tools put powerful photo manipulation features \u2014 the kinds of edits that were previously only available with some Photoshop knowledge and hours of work \u2014 into everyone\u2019s hands and encourage them to be used on a wide scale, without any particular guardrails or consideration for what that might mean. Suddenly, almost any photo you take can be instantly turned into a fake.\nPeters is right in general, but I think his specific pessimism is misguided. Tools like these are not exclusive to Google\u2019s products, and they are not even that new. Adobe recently added\nGenerative Fill\nto Photoshop, for example, which does the same kind of stuff as the Magic Eraser and Magic Editor. It augments the Content Aware Fill option which has been part of Photoshop since 2010. The main difference is that Content Aware Fill works the way the old Magic Eraser used to: by sampling part of the real image to create a patch, though Adobe has\nmarketed it as an \u201cartificial intelligence\u201d feature\nbefore the current wave of \u201cA.I.\u201d hype began.\nFor what it is worth, I tried that with one of the examples from Google\u2019s Pixel 8 video. You know that scene where the Magic Editor is used to remove the trampoline from a slam dunk?\nA screenshot from Google\u2019s Pixel 8 marketing video.\nI roughly selected the area around the trampoline, and used the Content Aware Fill to patch that area. It took two passes but was entirely automatic:\nThe same screenshot, edited in Adobe\u00ae Photoshop\u00ae software.\nIs it perfect? No, but it is fine. This is with technology that debuted thirteen years ago. I accomplished this in about ten seconds and not, as Peters claims, \u201chours\u201d. It barely took meaningful knowledge of the software.\nThe worries about Content Aware Fill are familiar, too. At the time it came out, Dr. Bob Carey, then president of the U.S.-based National Press Photographers Association, was\nquoted in a Photoshelter blog post\nsaying that \u201cif an image has been altered using technology, the photo consumer needs to know\u201d. Without an adequate disclaimer of manipulation, \u201cimages will cease to be an actual documentation of history and will instead become an altered history\u201d.\n3\nAccording to Peters, Google says the use of its \u201cMagic\u201d generative features will add metadata to the image file, though it says \u201cBest Take\u201d images will not. Metadata can be manipulated with software like\nExifTool\n. Even data wrappers explicitly intended to avoid any manipulation, like digital rights management, can be altered or removed. We are right back where we started: photographs are purportedly light captured in time, but this assumption has always been undermined by changes which may not be obvious or disclosed.\nHere is where I come clean: while it may seem like I did a lot of research for this piece, I cannot honestly say I did. This is based on writing about this topic for years, a lot of articles and journal papers I read, one class I took a long time ago, and an exhibition catalogue I borrowed from the\nlibrary\n. I also tried my best to fact-check everything here. Even though I am not an expert, it made my head spin to see the same concerns dating back to the mid-nineteenth century. We are still asking the same things, like\ncan I trust this photo?\n, and it is as though we have not learned the answer is that\nit depends\n.\nI, too, have\ncriticized\ncomputational photography. In particular, I\nquestioned the ethics\nof Samsung\u2019s trained image model, made famous by its\nMoon zoom\nfeature. Even though I knew there has been a long history of inauthentic images, something\ndoes\nfeel different about a world in which cameras are, almost by default, generating more perfect photos for us \u2014 images that are based on a real situation, but not accurately reflecting it.\nThe criticisms I have been seeing about the features of the Pixel 8, however, feel like we are only repeating the kinds of fears of nearly two hundred years. We have not been able to wholly trust photographs pretty much since they were invented. The only things which have changed in that time are the ease with which the manipulations can happen, and their availability. That has risen in tandem with a\nplanet full of people\ncarrying a camera everywhere. If you believe the estimates, we take\nmore photos every two minutes\nthan existed for the first hundred-and-fifty years after photography\u2019s invention. In one sense, we are now fully immersed in an environment where we cannot be certain of the authenticity of anything.\nThen again, Bigfoot and Loch Ness monster sightings are on a real decline.\nWe all live with a growing sense that everything around us is fraudulent. It is striking to me how these tools have been introduced as confidence in institutions has declined. It feels like a death spiral of trust \u2014 not only are we expected to separate facts from their potentially misleading context, we increasingly feel doubtful that any experts are able to help us, yet we keep inventing new ways to distort reality.\nEven this article cannot escape that spectre, as you cannot be certain I did not generate it with a large language model. I did not; I am not nearly enough of a dope to\nuse that punchline\n. I hope you can believe that. I hope you can trust me, because that is the same conclusion drawn by Fineman in \u201cFaking It\u201d:\n4\nJust as we rely on journalists (rather than on their keyboards) to transcribe quotes accurately, we must rely on photographers and publishers (rather than on cameras themselves) to guarantee the fidelity of photographic images when they are presented as facts.\nThe questions that are being asked of the Pixel 8\u2019s image manipulation capabilities are good and necessary because there are real ethical implications. But I think they need to be more fully contextualized. There is a long trail of exactly the same concerns and, to avoid repeating ourselves yet again, we should be asking these questions with that history in mind. This era feels different. I think we should be asking more precisely why that is.\nI am writing this in the wake of another Google-related story that dominated the tech news cycle this week, after\nMegan Gray claimed\n, in an article for\nWired\n, that the company had revealed it replaces organic search results with ones which are more lucrative. Though it faced immediate skepticism and Gray presented no proof, the claim was widely re-published; it\nfeels\ntrue. Despite days of questioning, the article stayed online without updates or changes \u2014 until, it seems, the\nAtlantic\n\u2019s Charlie Warzel\nasked about it\n. The article has now been\nreplaced with a note\nacknowledging it \u201cdoes not meet our [\nWired\n\u2019s] editorial standards\u201d.\nGray also said nothing publicly in response to questions about the article\u2019s claims between when it was published on Monday morning to its retraction. In an\ninterview with Warzel\npublished after the article was pulled, Gray said \u201cI stand by my larger point \u2014 the Google Search team and Google ad team worked together to secretly boost commercial queries\u201d \u2014 but this, too, is not supported by available documentation and it is something Google also denies. This was ultimately a mistake. Gray, it seems, interpreted a slide shown briefly during the trial in the way her biases favoured.\nWired\nchose to publish the article in its \u201cIdeas\u201d opinion section despite the paucity of evidence. I do not think there was an intent to deceive, though I find the response of both responsible parties lacking \u2014 to say the least.\nIntention matters. If a friend showed you a photo of them apparently making an amazing slam dunk, you would mentally check it against what you know about their basketball skills. If it does not make sense, you might start asking whether the photo was edited, or carefully framed or cropped to remove something telling, or a\nclever composite\n. This was true before you knew about that Pixel 8 feature. What is different now is that it is a little bit easier for that friend to lie to you. But that breach of trust is because of the lie, not because of the mechanism.\nThe questions we ask about generative technologies should acknowledge that we already have plenty of ways to lie, and that lots of the information we see is suspect. That does not mean we should not believe anything, but it does mean we ought to be asking questions about what is changed when tools like these become more widespread and easier to use.\nWe put our trust in people to help us evaluate information. Even people who have no faith in institutions and experts have\nsomething\nthey see as reputable, regardless of whether it actually is. Generative tools only add to the existing inundation of questionably-sourced media. Something\nfeels\ndifferent about them, but I am not entirely sure anything is actually different. We still need to skeptically \u2014 but not cynically \u2014 evaluate everything we see.\nUpdate:\nCorrected my thrice-written misuse of \u201cjump shot\u201d to \u201cslam dunk\u201d because I am bad at sports. Also, I have replaced the use of \u201cbench\u201d with \u201ctrampoline\u201d because that is what that object in the photo is.\nPage 7 in the hardcover MoMA edition.\n\u21a5\ufe0e\nPage XIII in the hardcover MoMA edition.\n\u21a5\ufe0e\nFor full disclosure, I did some contractual design work for Photoshelter several years ago.\n\u21a5\ufe0e\nPage 43 in the hardcover MoMA edition.\n\u21a5\ufe0e\nOlder\nThe Pixel Pinky Promise\nNewer\nThe Markup\u2019s Uncredited Reporting in the Wall Street Journal\nSubscribe on Patreon\n.\nFollow Pixel Envy with\nMastodon\n,\nRSS\n,\nJSON\n, or\nApple News\n. I use\nlocal limited analytics\nand web font files; you can\nopt out\nany time.\n\u00a9 Nick Heer\nSearch for:\nAssembled from bits daily in Calgary and around the world.\nThank you for reading."
        }, {
            "title": "2023: The Year of AI",
            "url": "https://journal.everypixel.com/2023-the-year-of-ai",
            "text": "2023: The Year of AI. The most remarkable releases, partnerships, and legal debates\nEverypixel Journal\nAbout\nCompany\n2023: The Year of AI\nAI has undoubtedly made waves in 2023 and here we spotlight the most significant stories of the year poised to shape the future of this groundbreaking industry:\nCorrection: In the original blog post published on December 22, 2023, the title \u201cAI Releases\u201d caused confusion as the content encompassed announcements and updates in addition to releases. We clarified the title of the text and infographic. The mention of Stability AI open-sourcing its LLM was excluded from the infographic but left in the article, underscoring its significance in promoting accessibility rather than focusing on tech improvement. The infographic initially featured the establishment of the xAI startup, now removed because of irrelevance. Additionally, the mention of Apple Vision Pro was excluded as the article focuses on software. We also included Midjourney V.6 in the list as it is a very recent release.\nThese adjustments aim to improve accuracy and coherence. We apologize for any confusion and appreciate your understanding!\nAI Advancements\nIn the landscape of AI advancements this year, notable progress was made, refining existing technologies rather than introducing groundbreaking innovations akin to the\nChatGPT or image generators of the previous year\n. While there was no wow effect and the real Artificial General Intelligence (AGI) is still far away, this year marked an intermediate stage between prior breakthroughs and something even more powerful to come. To showcase this evolution, we crafted a visual timeline, highlighting the most remarkable AI advancements that have shaped this year of AI:\nImage Generation\nAdobe Firefly:\nAdobe\u2019s Firefly\nand\nGenerative Fill\nempowered diverse visual content creation, including illustrations, art concepts, and photo manipulation.\nIntegrated into Photoshop\n, Adobe Firefly democratized AI, extending its power to a broad user base at once. The release of the\nText Effect feature\nalso marked a significant stride, allowing users to apply styles or textures to words and phrases.\nMidjourney:\nMidjourney\u2019s V.5 model\nmarked a milestone in image generation, showcasing improved efficiency, coherence, and higher resolution. The latest alpha-version,\nMidjourney V.6\n, brought additional enhancements such as more accurate prompt following, increased model knowledge, and minor text drawing ability.\nDALL\u00b7E 3:\nBuilt on ChatGPT,\nDALL\u00b7E 3\nsimplified image generation, eliminating the need for complex prompt engineering. In addition, ChatGPT introduced a feature to help users refine prompts and make image adjustments based on feedback.\nShutterstock.AI:\nThe stock image giant\nintegrated AI capabilities\n, allowing users to transform prompts into license-ready imagery. Recognizing and rewarding contributing artists, Shutterstock made the first step in ethical AI.\nThe Evolution of Text-to-Image Algorithms, 2007 vs 2023\nVideo Generation\nStability AI:\nStability AI\nintroduced Stable Video Diffusion\n, a groundbreaking model for generative video, with open-source access on GitHub. Drawing a parallel to\nAI image generation trends\n, it\u2019s highly possible that the Stable Video Diffusion model will play a pivotal role in the creation of a significant portion of AI-generated videos.\nHeyGen:\nAI startup unveiled\na tool for voice cloning\n, lip movement adjustments, and language translation in videos.\nRunway Gen-2\n:\nRunway launched the Gen-2\nmodel, enabling users to effortlessly generate full-blown videos from just text prompts, images, or other videos. Just have a look at the example below.\nPika and Pika 1.0\n: With its initial release, Pika garnered half a million users, generating millions of videos weekly. Then upgraded AI model in\nPika 1.0\nempowered users to create and edit videos in various styles, including 3D animation, anime, cartoon, and cinematic.\nCodec avatars by Meta:\nMeta\u2019s Pixel Codec Avatars\n(PiCA) model for 3D human faces in videos brought us closer to photorealistic telepresence.\nTurn words into worlds with the most advanced text to video AI model: Gen-2\nAny story. Every style. Completely generated.\nhttps://t.co/ekldoIshdw\npic.twitter.com/q1xK84hpd1\n\u2014 Runway (@runwayml)\nDecember 4, 2023\nText Generation\nBard and Gemini:\nGoogle\u2019s Bard\nadded human-like emotion and sentiment to the chatbot landscape. Introduced into Bard chatbot and trained on a multimodal dataset,\nGoogle\u2019s Gemini\nemerged as the \u201cmost capable\u201d AI model and the closest competitor to OpenAI\u2019s ChatGPT.\nGrok:\nElon Musk\u2019s startup xAI\nsignaled a commitment to AI development, potentially competing with OpenAI, by\nunveiling \u201cGrok\u201d\n\u2014 a chatbot with humor, rebelliousness, and real-time knowledge via the \ud835\udd4f platform. The xAI promised that Grok\nwas designed to answer provocative questions\nrejected by other AI systems.\nOverflowAI:\nStack Overflow\u2019s OverflowAI\nenhanced knowledge curation, enabling AI-powered search for relevant answers in Visual Studio Code and Slack.\nLlama 2:\nMeta released Llama 2\n, the next generation of its open-source large language model, showcasing enhanced efficiency. Meta\u2019s fine-tuned LLM was also optimized for dialogue use cases and outperformed other open-source models on most benchmarks.\nGPT-4:\nOpenAI\u2019s GPT-4\nnow handles image input, generates captions, classifications, hears, and responds in a back-and-forth conversation, and supports\nreal-time web browsing\n. OpenAI also extended support for plugins, fostering a landscape enriched with open-source competitors. GPT-4 is the next step in OpenAI\u2019s journey to develop AGI.\nMistral 7B:\nMistral AI\n,\nvalued at around $2 billion\nthis year, released Mistral 7B, a large language model challenging GPT-4 and Claude 2. Emphasizing an open technology approach, Mistral AI offered its model for free download.\nMixtral 8x7B:\nMistral AI also introduced Mixtral 8x7B\n, a high-quality sparse mixture of expert model (SMoE) with open weights, featuring 46.7B total parameters, pioneering openness in models with enhanced truthfulness and reduced biases.\nYi-34B llm:\nValued at $1 billion\nthis year, Kai-Fu Lee\u2019s startup\n01.AI\nreleased Yi-34B \u2014 an open-source neural network that outperformed competing models with significantly higher parameter counts, emphasizing its cost-efficiency.\nOther Advancements:\nSegment Anything Model (SAM):\nMeta AI presented SAM\n, a segmentation model capable of \u201ccutting out\u201d objects in images without additional training, underscoring its adaptability. SAM was trained on a vast dataset, showcasing its robust performance in object segmentation.\nDirect Preference Optimization (DPO):\nDPO emerged\nas a stable and efficient method for fine-tuning large-scale unsupervised language models and teaching text-to-image models. It achieved precise control without complex reinforcement learning from human feedback (RLHF).\nZephyr Direct Distillation of LM Alignment:\nZephyr-7B\n, a result of distilled direct preference optimization (dDPO), set the benchmark for chat models with 7B parameters, enhancing intent alignment without extensive training.\nAutonomous AI Agents:\nAutonomous AI agents emerged\nas a notable trend, showcasing a transformative shift toward advanced and autonomous AI systems. AI Agents are considered a first glimpse of AGI as they can generate self-directed tasks and instructions based on a user\u2019s goal, and work on them autonomously until the goal is achieved.\nEvoDiff:\nMicrosoft\u2019s EvoDiff\n, an open-source AI framework for fast and cost-saving protein generation, promised advancements in therapeutics and industrial applications.\nStable Audio:\nStability AI launched\na tool for generating short high-quality audio clips from simple text prompts.\nGPT Store, Copyright Shield, ChatGPT Bot Constructor:\nOpenAI introduced\nthe GPT Store to sell custom GPT bots, Copyright Shield to cover legal costs related to copyright infringement claims, and a no-code platform for custom ChatGPT versions.\nStability AI Open-Sourced its LLM:\nStability AI has open-sourced its models\n, StableLM-Alpha and Stable Vicuna, renowned for their impressive performance in generating text and code. Stable Vicuna is the first open-source chatbot trained using reinforcement learning from human feedback (RLHF). Furthermore, Stability AI\nunveiled SDXL Turbo\n, a real-time text-to-image generation model.\nPartnerships\nIn the dynamic realm of 2023, significant collaborations have surfaced among industry leaders, shaping the trajectory of the future. Here are the top merges and partnerships that were defining the AI landscape in this year 2023:\nStability AI and Init ML\nStability AI has made a significant move by\nacquiring Init ML\n, the brains behind the popular editing app ClipDrop. The objective was clear:\nintegrate Stability AI\u2019s advanced technologies\ninto ClipDrop\u2019s ecosystem. The collaboration has already resulted in the\ndevelopment of SDXL Turbo\n.\nRunway and Getty\nImages\nRunway has joined forces with Getty Images\nin a strategic partnership to introduce a new video generation model RGM (The Runway and Getty Images Model). The model combines Runway\u2019s AI capabilities with Getty Images\u2019 licensed creative content library. The collaboration aims to revolutionize content creation workflows, enabling companies to generate high-quality, customized videos tailored to their brand identities.\nSnowflake and Neeva\nSnowflake, a major player in the data warehouse platform,\nhas acquired Neeva\n, a startup known for using generative AI to enhance the search experience. Neeva had recently closed its subscription-based, ad-free search engine. The founders of Neeva also acknowledged the challenge of convincing users to try a new search engine.\nShutterstock and OpenAI\nShutterstock and OpenAI have committed\nto an extended 6-year partnership. OpenAI gained access to high-quality data from Shutterstock, enriching its model training datasets with a diverse range of images, videos, and music libraries. Shutterstock continued to leverage OpenAI\u2019s technologies, leading to the launch of Shutterstock\u2019s AI image-generating tool.\nLegal Landscape\nIn the ever-evolving legal realm of AI, 2023 finds itself amidst a landscape filled with uncertainties and ongoing debates. As new challenges emerge, discussions surrounding copyright, corporate policies, and the broader regulatory framework continue, shaping the contours of AI\u2019s legal landscape. Here are the most important legal issues of the year 2023:\nEuropean AI Act\nThe\nEuropean Union introduced the AI Act\n, the world\u2019s first comprehensive law, to regulate the use of AI. The act classifies AI systems based on the risk they pose and sets forth regulations accordingly. Although the AI Act has been provisionally agreed upon, its implementation faces delays, and the enforcement won\u2019t commence until 2025.\nU.S. Copyright Office Stance on Registration of AI-Generated Content\nThe U.S. Copyright Office took a decisive stance,\ndenying copyright\nregistration for images created by the AI algorithm Midjourney. The rejection set a precedent, asserting that AI artworks solely created by AI, without human involvement, are ineligible for copyright protection. In the same vein, the\nU.S. Copyright Office issued guidance\non AI-assisted works, clarifying that works created by humans using AI tools may be eligible for copyright protection. The guidance confirmed that works created by humans using AI tools should be evaluated based on whether the human role in the creation of those works was determinative.\n\u201cCurrently, the existing legal system is not prepared to acknowledge copyright for works created with AI, given that AI learns from existing data, the rights to which belong to other people, challenging the attribution of ownership. The practice for addressing this issue is expected to develop next year, facilitated by public participation through\nstate-conducted surveys\n. Resolving this matter independently is now difficult without broader public engagement.\u201d\nDaria Kuznetsova, Corporate Lawyer of Everypixel\nMcKinsey\nalso released a comprehensive graph capturing the most important AI governance-related policy and regulatory efforts in 2023. The visual representation highlights the significant contributions of 2023 in shaping the legal landscape of AI.\nSource:\nMcKinsey\nDebates\nThe year 2023 was abuzz with intriguing debates and discussions, grappling with uncertainties and the evolving norms of the AI landscape. As the industry shapes its course, these debates become inevitable, promising more thought-provoking dialogues and challenges on the horizon. Here are some of the most noteworthy debates that defined the year:\nCorporate Restrictions on ChatGPT\nMajor financial institutions, including JP Morgan, Citigroup, Bank of America, Deutsche Bank, Goldman Sachs, and Wells Fargo & Co,\nhave restricted ChatGPT usage\ndue to security and privacy concerns. This reflected a broader trend where companies were issuing warnings to employees about the legal considerations associated with AI applications in corporate environments.\nOpenAI\u2019s Use of Low-Paid Workers\nTime\u2019s investigation exposed OpenAI\u2019s collaboration with Sama,\nemploying low-paid workers in Kenya\nto sift through sensitive content for ChatGPT. The revelation raised ethical questions about the treatment of workers and the impact of content moderation on mental well-being.\nLeadership Transition at OpenAI\nSam Altman\u2019s departure\nand quick return made headlines last month. A leadership transition unfolded at OpenAI as Sam Altman stepped down amid communication inconsistencies with the board. Interim CEO Mira Murati, along with a majority of staff, advocated for Altman\u2019s return. This unprecedented situation attracted widespread attention, leaving questions about the true reasons behind the transition and future implications.\nAdobe and Figma\nAdobe\u2019s $20 billion acquisition plan for Figma\nencountered regulatory hurdles, prompting investigations by the European Commission and the UK Competition and Markets Authority over potential antitrust issues. The proposed deal\u2019s impact also extended beyond design considerations, as Adobe\u2019s dominance in customer data platforms raised concerns among Chief Information Officers (CIOs) about its potential influence on cloud software spending. However,\nAdobe abandoned the deal\ndue to challenges in securing antitrust approvals in Europe and the UK, resulting in a termination fee of $1 billion to Figma.\nPhotographer Hacked the World Photography Awards\nPhotographer Boris Eldagsen\ndisrupted the Sony World Photography Awards\nby submitting AI-generated artwork. Eldagsen\u2019s refusal to accept the prize sparked a debate on the place of AI-generated images in traditional photography competitions, challenging perceptions of authenticity and creativity.\nSpread the word\nPosted\n22.12.2023\nin\nTrends and Forecasts\nby\nKristina Korotenko\nTags:\nAdobe\n,\nAdobe Firefly\n,\nAdobe Photoshop\n,\nAI\n,\nAI content creation\n,\nAI news\n,\nAI tools\n,\nApple\n,\nBard\n,\nChatGPT\n,\nClipDrop\n,\nCopyright\n,\nDALL-E\n,\nElon Musk\n,\nEvoDiff\n,\ngenerative AI tools\n,\nGetty Images\n,\nGPT-4\n,\nMeta\n,\nmetaverse\n,\nMicrosoft\n,\nMidjourney\n,\nOpenAI\n,\nOpenAI CEO\n,\nOverflowAI\n,\nShutterstock\n,\nStability AI\n,\nStable Diffusion\n,\nStack Overflow\nEverypixel Journal\nProudly powered by Everypixel\n\u00a9 2023\nPages\nAbout\nCompany\nSocial\nFacebook\nInstagram\nTwitter"
        }
    ]
}
